services:
  # Step 1 — scraper: writes /data/news.jsonl then exits 0
  scraper:
    build: ./services/scraper
    volumes:
      - ./services/scraper:/app
      - ./artifacts:/data
      - ./secrets/sa-key.json/newsjuice-123456-aec40a8f14f5.json:/run/secrets/gcp.json:ro
    environment:
      GOOGLE_APPLICATION_CREDENTIALS: /run/secrets/gcp.json
      DATABASE_URL: "postgresql://postgres:Newsjuice25%2B@dbproxy:5432/newsdb"
    working_dir: /app
    command:
      - sh
      - -lc
      - >
        /home/app/.venv/bin/python wait_for_db.py
        && exec /home/app/.venv/bin/python scraper.py --out /data/news.jsonl
    restart: "no"

  # Step 2 — loader: reads the /data/news.jsonl file, chunks+embeds, loads to vector DB
  loader:
    build: ./services/loader
    depends_on:
      - dbproxy
    volumes:
      - ./services/loader:/app
      - ./artifacts:/data
      - ./secrets/sa-key.json/newsjuice-123456-aec40a8f14f5.json:/run/secrets/gcp.json:ro
    environment:
      GOOGLE_APPLICATION_CREDENTIALS: /run/secrets/gcp.json
      DATABASE_URL: "postgresql://postgres:Newsjuice25%2B@dbproxy:5432/newsdb"
    working_dir: /app
    command:
      - sh
      - -lc
      - >
        /home/app/.venv/bin/python wait_for_db.py
        && exec /home/app/.venv/bin/python loader.py --out /data/news.jsonl
    restart: "no"

  # Step 3 — retriever API: Manager calls POST /retrieve
  retriever:
    build: ./services/retriever
    depends_on:
      - dbproxy
    volumes:
      - ./services/retriever:/app
      - ./artifacts:/data
      - ./secrets/sa-key.json/newsjuice-123456-aec40a8f14f5.json:/run/secrets/gcp.json:ro
    environment:
      GOOGLE_APPLICATION_CREDENTIALS: /run/secrets/gcp.json
      DATABASE_URL: "postgresql://postgres:Newsjuice25%2B@dbproxy:5432/newsdb"
      FETCH_K: "30"           # overfetch chunks
      DOCS_K: "3"             # return top unique docs
      RECENCY_LAMBDA: "0.0"   # try 0.03–0.07 to bias recent
    working_dir: /app
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-fsS", "http://localhost:8000/health"]
      interval: 15s
      timeout: 5s
      retries: 5

  # Step 4 — (optional) summarizer service (add when ready)
  summarizer:
    build: ./services/summarizer
    volumes:
      - ./services/summarizer:/app
    environment:
      GROQ_API_KEY: "${GROQ_API_KEY}"
      GROQ_MODEL: "llama-3.3-70b-versatile"
    working_dir: /app
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-fsS", "http://localhost:8000/health"]
      interval: 15s
      timeout: 5s
      retries: 5

  # Manager — orchestrates retriever (and summarizer when available)
  manager:
    build: ./services/manager
    depends_on:
      - retriever
      - summarizer
    volumes:
      - ./services/manager:/app
      - ./artifacts:/data
    environment:
      RETRIEVER_URL: "http://retriever:8000/retrieve"
      SUMMARIZER_URL: "http://summarizer:8000/summarize"
      HISTORY_PATH: "/data/user_history.jsonl"
      DOCS_K: "3"  # internal default if you keep it in Manager
    working_dir: /app
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-fsS", "http://localhost:8000/health"]
      interval: 15s
      timeout: 5s
      retries: 5

  # Cloud SQL Auth Proxy to reach your DB
  dbproxy:
    image: gcr.io/cloud-sql-connectors/cloud-sql-proxy:2
    command:
      - "--port=5432"
      - "--address=0.0.0.0"
      - "--credentials-file=/run/secrets/gcp.json"
      - "newsjuice-123456:us-central1:newsdb-instance"
    volumes:
      - ./secrets/sa-key.json/newsjuice-123456-aec40a8f14f5.json:/run/secrets/gcp.json:ro
    restart: unless-stopped
